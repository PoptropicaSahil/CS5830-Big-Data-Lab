{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# import wget\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2008\n",
    "\n",
    "url = f\"https://www.ncei.noaa.gov/data/local-climatological-data/access/{year}/\"\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Step 2: Parse the HTML and extract links\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "# links = soup.find_all('a', href=True, attrs={'href': lambda href: href.endswith('.csv')})\n",
    "links = soup.find_all('a', href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_hrefs = [link['href'] for link in links if re.match(r\".+\\.csv$\", link['href'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01001099999.csv',\n",
       " '01001499999.csv',\n",
       " '01003099999.csv',\n",
       " '01007099999.csv',\n",
       " '01008099999.csv',\n",
       " '01010099999.csv',\n",
       " '01014099999.csv',\n",
       " '01015099999.csv',\n",
       " '01023099999.csv',\n",
       " '01023199999.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_hrefs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_urls = [url + csv_name for csv_name in csv_hrefs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11676"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(download_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01001099999.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01001499999.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01003099999.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01007099999.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01008099999.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01010099999.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01014099999.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01015099999.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01023099999.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/01023199999.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_urls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic for loop\n",
    "# useful_df = []\n",
    "# n_locs = 5\n",
    "\n",
    "# for idx, url in enumerate(download_urls):\n",
    "#     df = pd.read_csv(url)\n",
    "#     monthly_agg_cols = [i for i in df.columns if i.startswith('Monthly')]\n",
    "#     df_agg = df[ monthly_agg_cols]\n",
    "#     print(f'read {idx+1} csv')\n",
    "#     if df_agg.isnull().all().all():\n",
    "#         print('not useful df')\n",
    "#     else:\n",
    "#         useful_df.append(url)\n",
    "#         print(f'useful df found')\n",
    "\n",
    "#     if len(useful_df) == n_locs:\n",
    "#         print(f'found enough urls, breaking...')\n",
    "#         break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not for jupyter\n",
    "# import concurrent.futures\n",
    "# import pandas as pd\n",
    "\n",
    "# useful_df = []\n",
    "# n_locs = 5\n",
    "\n",
    "# # Define the download_urls\n",
    "# # download_urls = [...]  # Your list of download URLs\n",
    "\n",
    "# def process_url(url):\n",
    "#     df = pd.read_csv(url)\n",
    "#     monthly_agg_cols = [i for i in df.columns if i.startswith('Monthly')]\n",
    "#     df_agg = df[monthly_agg_cols]\n",
    "    \n",
    "#     if not df_agg.isnull().all().all():\n",
    "#         useful_df.append(url)\n",
    "#         print(f'***** useful df found for {url}')\n",
    "#         if len(useful_df) == n_locs:\n",
    "#             print('Found enough URLs, breaking...')\n",
    "\n",
    "# with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#     executor.map(process_url, download_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0000953862.csv\n",
      "Read 2 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0003225715.csv\n",
      "Read 3 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0002363890.csv\n",
      "Found enough URLs, breaking...\n",
      "Read 4 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0001263879.csv\n",
      "Read 5 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0001163848.csv\n",
      "Read 6 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0001704868.csv\n",
      "Read 7 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0002163884.csv\n",
      "Read 8 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0001953969.csv\n",
      "Read 9 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0000812978.csv\n",
      "Read 10 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0002453848.csv\n",
      "Read 11 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0003103725.csv\n",
      "Read 12 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994290.csv\n",
      "Read 13 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0000453929.csv\n",
      "Read 14 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0000253928.csv\n",
      "Read 15 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0000363844.csv\n",
      "Read 16 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0000594076.csv\n",
      "Read 17 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0001363847.csv\n",
      "Read 18 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994645.csv\n",
      "Read 19 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994995.csv\n",
      "Read 20 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994084.csv\n",
      "Read 21 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994082.csv\n",
      "Read 22 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994088.csv\n",
      "Read 23 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994644.csv\n",
      "Read 24 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994996.csv\n",
      "Read 25 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994080.csv\n",
      "Read 26 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994085.csv\n",
      "Read 27 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994078.csv\n",
      "Read 28 csv\n",
      "not useful df https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999993816.csv\n",
      "Read 29 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994079.csv\n",
      "Read 30 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999992811.csv\n",
      "Read 31 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999973803.csv\n",
      "Read 32 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994081.csv\n",
      "Read 33 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999993245.csv\n",
      "Read 34 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994075.csv\n",
      "Read 35 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999973802.csv\n",
      "Read 36 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994060.csv\n",
      "Read 37 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994077.csv\n",
      "Read 38 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999992827.csv\n",
      "Read 39 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994059.csv\n",
      "Read 40 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999993243.csv\n",
      "Read 41 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999964758.csv\n",
      "Read 42 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994074.csv\n",
      "Read 43 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999992821.csv\n",
      "Read 44 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999964756.csv\n",
      "Read 45 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999963897.csv\n",
      "Read 46 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999963896.csv\n",
      "Read 47 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999963899.csv\n",
      "Read 48 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999992826.csv\n",
      "Read 49 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999964757.csv\n",
      "Read 50 csv\n",
      "***** useful df found for https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999963898.csv\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import threading\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "useful_df = []\n",
    "n_locs = 2\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Define the download_urls\n",
    "files_read = 0  # Initialize files_read\n",
    "\n",
    "def process_url(url):\n",
    "    global files_read\n",
    "\n",
    "    # cols_to_read = ['MonthlyAverageRH', 'MonthlyDewpointTemperature', 'MonthlyMeanTemperature',\n",
    "    #                 'MonthlySeaLevelPressure', 'MonthlyStationPressure', 'MonthlyTotalLiquidPrecipitation',\n",
    "    #                 'MonthlyTotalSnowfall','MonthlyWetBulb']\n",
    "    cols_to_read = ['MonthlyMeanTemperature']\n",
    "\n",
    "    df = pd.read_csv(url, usecols = cols_to_read)\n",
    "    # monthly_agg_cols = [i for i in df.columns if i.startswith('Monthly')]\n",
    "    # df_agg = df[monthly_agg_cols]\n",
    "\n",
    "    # df_agg = df.copy()\n",
    "\n",
    "    with lock:\n",
    "        files_read += 1\n",
    "        print(f'Read {files_read} csv', flush=True)\n",
    "\n",
    "    if df.isnull().all().all(): # df_agg\n",
    "        print(f'not useful df {url}')\n",
    "    else:\n",
    "        useful_df.append(url)\n",
    "        print(f'***** useful df found for {url}')\n",
    "        \n",
    "        with lock:\n",
    "            if len(useful_df) == n_locs:\n",
    "                print('Found enough URLs, breaking...')\n",
    "                return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    num_files_to_read = n_locs * 10\n",
    "    executor.map(process_url, download_urls[::-1][:num_files_to_read])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0000953862.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0002363890.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0002453848.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994290.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994645.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994995.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994084.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994082.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994088.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994644.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994996.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994080.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994085.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994078.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994079.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999992811.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999973803.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994081.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999993245.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994075.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999973802.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994060.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994077.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999992827.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994059.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999993243.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999964758.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994074.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999992821.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999964756.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999963897.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999963896.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999963899.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999992826.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999964757.csv',\n",
       " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999963898.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_default_links = ['https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0000953862.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0002363890.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/A0002453848.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994290.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994645.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994995.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994084.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994082.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994088.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994644.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994996.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994080.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994085.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994078.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994079.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999992811.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999973803.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994081.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999993245.csv',\n",
    " 'https://www.ncei.noaa.gov/data/local-climatological-data/access/2008/99999994075.csv',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21528\\3385121453.py:7: DtypeWarning: Columns (10,12,27,33,34,35,37,38,39,43,44,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(link)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21528\\3385121453.py:7: DtypeWarning: Columns (7,8,17,18,36,38,39,50,66,71) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(link)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21528\\3385121453.py:7: DtypeWarning: Columns (23,43,47,48,49,51,108,111,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(link)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m csv_name \u001b[38;5;241m=\u001b[39m link\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, csv_name)\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# wget.download(link, filename)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:377\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    375\u001b[0m             \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n\u001b[0;32m    376\u001b[0m             compression \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 377\u001b[0m         reader \u001b[38;5;241m=\u001b[39m BytesIO(\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    379\u001b[0m         filepath_or_buffer\u001b[38;5;241m=\u001b[39mreader,\n\u001b[0;32m    380\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    383\u001b[0m         mode\u001b[38;5;241m=\u001b[39mfsspec_mode,\n\u001b[0;32m    384\u001b[0m     )\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_fsspec_url(filepath_or_buffer):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:489\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 489\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[0;32m    491\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:638\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[0;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[0;32m    640\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wget\n",
    "data_dir = \"../data/default\"\n",
    "for idx, link in enumerate(df_default_links):\n",
    "    csv_name = link.split(\"/\")[-1]\n",
    "    filename = os.path.join(data_dir, csv_name)\n",
    "\n",
    "    df = pd.read_csv(link)\n",
    "    df.head()\n",
    "    # wget.download(link, filename)\n",
    "\n",
    "    if idx == 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = ['https://www.ncei.noaa.gov/data/local-climatological-data/access/2012/99999994728.csv',\n",
    "       'https://www.ncei.noaa.gov/data/local-climatological-data/access/2012/99999994290.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in dfs:\n",
    "    df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonthlyAverageRH</th>\n",
       "      <th>MonthlyDewpointTemperature</th>\n",
       "      <th>MonthlyMeanTemperature</th>\n",
       "      <th>MonthlySeaLevelPressure</th>\n",
       "      <th>MonthlyStationPressure</th>\n",
       "      <th>MonthlyTotalLiquidPrecipitation</th>\n",
       "      <th>MonthlyTotalSnowfall</th>\n",
       "      <th>MonthlyWetBulb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MonthlyAverageRH  MonthlyDewpointTemperature  MonthlyMeanTemperature  \\\n",
       "0               NaN                         NaN                     NaN   \n",
       "1               NaN                         NaN                     NaN   \n",
       "2               NaN                         NaN                     NaN   \n",
       "3               NaN                         NaN                     NaN   \n",
       "4               NaN                         NaN                     NaN   \n",
       "\n",
       "   MonthlySeaLevelPressure  MonthlyStationPressure  \\\n",
       "0                      NaN                     NaN   \n",
       "1                      NaN                     NaN   \n",
       "2                      NaN                     NaN   \n",
       "3                      NaN                     NaN   \n",
       "4                      NaN                     NaN   \n",
       "\n",
       "   MonthlyTotalLiquidPrecipitation  MonthlyTotalSnowfall  MonthlyWetBulb  \n",
       "0                              NaN                   NaN             NaN  \n",
       "1                              NaN                   NaN             NaN  \n",
       "2                              NaN                   NaN             NaN  \n",
       "3                              NaN                   NaN             NaN  \n",
       "4                              NaN                   NaN             NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_read = ['MonthlyAverageRH', 'MonthlyDewpointTemperature', 'MonthlyMeanTemperature',\n",
    "                'MonthlySeaLevelPressure', 'MonthlyStationPressure', 'MonthlyTotalLiquidPrecipitation',\n",
    "                'MonthlyTotalSnowfall','MonthlyWetBulb']\n",
    "df = pd.read_csv(\"https://www.ncei.noaa.gov/data/local-climatological-data/access/2010/01088699999.csv\",\n",
    "                  usecols = cols_to_read)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MonthlyAverageRH                   True\n",
       "MonthlyDewpointTemperature         True\n",
       "MonthlyMeanTemperature             True\n",
       "MonthlySeaLevelPressure            True\n",
       "MonthlyStationPressure             True\n",
       "MonthlyTotalLiquidPrecipitation    True\n",
       "MonthlyTotalSnowfall               True\n",
       "MonthlyWetBulb                     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Select the desired number of files\n",
    "selected_links = random.sample(links, n_locs)\n",
    "download_urls = [url + link['href'] for link in selected_links]\n",
    "# a03_logger.info(f'download_urls are {download_urls}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# output_file = \"data/processed/ground_truth.csv\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../outputs/processed/ground_truth.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m input_files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(input_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "input_dir = \"../data/raw\"\n",
    "# output_file = \"data/processed/ground_truth.csv\"\n",
    "output_file = \"../outputs/processed/ground_truth.csv\"\n",
    "input_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/raw\\\\48381099999.csv',\n",
       " '../data/raw\\\\54337099999.csv',\n",
       " '../data/raw\\\\57483099999.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATION                 DATE   LATITUDE   LONGITUDE  ELEVATION  \\\n",
      "0  48381099999  1960-01-01T07:00:00  16.466628  102.783661     204.21   \n",
      "\n",
      "            NAME REPORT_TYPE  SOURCE  HourlyAltimeterSetting  \\\n",
      "0  KHON KAEN, TH       FM-12       4                     NaN   \n",
      "\n",
      "   HourlyDewPointTemperature  ... BackupDirection  BackupDistance  \\\n",
      "0                         54  ...             NaN             NaN   \n",
      "\n",
      "  BackupDistanceUnit  BackupElements  BackupElevation  BackupEquipment  \\\n",
      "0                NaN             NaN              NaN              NaN   \n",
      "\n",
      "   BackupLatitude  BackupLongitude  BackupName  WindEquipmentChangeDate  \n",
      "0             NaN              NaN         NaN                      NaN  \n",
      "\n",
      "[1 rows x 125 columns]\n",
      "Index(['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME',\n",
      "       'REPORT_TYPE', 'SOURCE', 'HourlyAltimeterSetting',\n",
      "       'HourlyDewPointTemperature',\n",
      "       ...\n",
      "       'BackupDirection', 'BackupDistance', 'BackupDistanceUnit',\n",
      "       'BackupElements', 'BackupElevation', 'BackupEquipment',\n",
      "       'BackupLatitude', 'BackupLongitude', 'BackupName',\n",
      "       'WindEquipmentChangeDate'],\n",
      "      dtype='object', length=125)\n",
      "       STATION                 DATE   LATITUDE   LONGITUDE  ELEVATION  \\\n",
      "0  54337099999  1960-01-01T02:00:00  41.133333  121.116667       70.0   \n",
      "\n",
      "          NAME REPORT_TYPE  SOURCE  HourlyAltimeterSetting  \\\n",
      "0  JINZHOU, CH       FM-12       4                     NaN   \n",
      "\n",
      "  HourlyDewPointTemperature  ... BackupDirection  BackupDistance  \\\n",
      "0                         5  ...             NaN             NaN   \n",
      "\n",
      "  BackupDistanceUnit BackupElements  BackupElevation  BackupEquipment  \\\n",
      "0                NaN            NaN              NaN              NaN   \n",
      "\n",
      "   BackupLatitude BackupLongitude  BackupName  WindEquipmentChangeDate  \n",
      "0             NaN             NaN         NaN                      NaN  \n",
      "\n",
      "[1 rows x 125 columns]\n",
      "Index(['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME',\n",
      "       'REPORT_TYPE', 'SOURCE', 'HourlyAltimeterSetting',\n",
      "       'HourlyDewPointTemperature',\n",
      "       ...\n",
      "       'BackupDirection', 'BackupDistance', 'BackupDistanceUnit',\n",
      "       'BackupElements', 'BackupElevation', 'BackupEquipment',\n",
      "       'BackupLatitude', 'BackupLongitude', 'BackupName',\n",
      "       'WindEquipmentChangeDate'],\n",
      "      dtype='object', length=125)\n",
      "       STATION                 DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
      "0  57483099999  1960-01-01T08:00:00     30.65     113.65       30.0   \n",
      "\n",
      "                  NAME REPORT_TYPE  SOURCE  HourlyAltimeterSetting  \\\n",
      "0  FENSUIZUI NORTH, CH       FM-12       4                     NaN   \n",
      "\n",
      "   HourlyDewPointTemperature  ...  BackupDirection  BackupDistance  \\\n",
      "0                       30.0  ...              NaN             NaN   \n",
      "\n",
      "  BackupDistanceUnit BackupElements  BackupElevation  BackupEquipment  \\\n",
      "0                NaN            NaN              NaN              NaN   \n",
      "\n",
      "   BackupLatitude  BackupLongitude  BackupName  WindEquipmentChangeDate  \n",
      "0             NaN              NaN         NaN                      NaN  \n",
      "\n",
      "[1 rows x 125 columns]\n",
      "Index(['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME',\n",
      "       'REPORT_TYPE', 'SOURCE', 'HourlyAltimeterSetting',\n",
      "       'HourlyDewPointTemperature',\n",
      "       ...\n",
      "       'BackupDirection', 'BackupDistance', 'BackupDistanceUnit',\n",
      "       'BackupElements', 'BackupElevation', 'BackupEquipment',\n",
      "       'BackupLatitude', 'BackupLongitude', 'BackupName',\n",
      "       'WindEquipmentChangeDate'],\n",
      "      dtype='object', length=125)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file in input_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # print(df.head(1))\n",
    "    print(df.columns)\n",
    "    # monthly_agg = df.groupby(pd.Grouper(freq='M')).mean()\n",
    "    # dfs.append(monthly_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STATION',\n",
       " 'DATE',\n",
       " 'LATITUDE',\n",
       " 'LONGITUDE',\n",
       " 'ELEVATION',\n",
       " 'NAME',\n",
       " 'REPORT_TYPE',\n",
       " 'SOURCE',\n",
       " 'HourlyAltimeterSetting',\n",
       " 'HourlyDewPointTemperature',\n",
       " 'HourlyDryBulbTemperature',\n",
       " 'HourlyPrecipitation',\n",
       " 'HourlyPresentWeatherType',\n",
       " 'HourlyPressureChange',\n",
       " 'HourlyPressureTendency',\n",
       " 'HourlyRelativeHumidity',\n",
       " 'HourlySkyConditions',\n",
       " 'HourlySeaLevelPressure',\n",
       " 'HourlyStationPressure',\n",
       " 'HourlyVisibility',\n",
       " 'HourlyWetBulbTemperature',\n",
       " 'HourlyWindDirection',\n",
       " 'HourlyWindGustSpeed',\n",
       " 'HourlyWindSpeed',\n",
       " 'Sunrise',\n",
       " 'Sunset',\n",
       " 'DailyAverageDewPointTemperature',\n",
       " 'DailyAverageDryBulbTemperature',\n",
       " 'DailyAverageRelativeHumidity',\n",
       " 'DailyAverageSeaLevelPressure',\n",
       " 'DailyAverageStationPressure',\n",
       " 'DailyAverageWetBulbTemperature',\n",
       " 'DailyAverageWindSpeed',\n",
       " 'DailyCoolingDegreeDays',\n",
       " 'DailyDepartureFromNormalAverageTemperature',\n",
       " 'DailyHeatingDegreeDays',\n",
       " 'DailyMaximumDryBulbTemperature',\n",
       " 'DailyMinimumDryBulbTemperature',\n",
       " 'DailyPeakWindDirection',\n",
       " 'DailyPeakWindSpeed',\n",
       " 'DailyPrecipitation',\n",
       " 'DailySnowDepth',\n",
       " 'DailySnowfall',\n",
       " 'DailySustainedWindDirection',\n",
       " 'DailySustainedWindSpeed',\n",
       " 'DailyWeather',\n",
       " 'MonthlyAverageRH',\n",
       " 'MonthlyDaysWithGT001Precip',\n",
       " 'MonthlyDaysWithGT010Precip',\n",
       " 'MonthlyDaysWithGT32Temp',\n",
       " 'MonthlyDaysWithGT90Temp',\n",
       " 'MonthlyDaysWithLT0Temp',\n",
       " 'MonthlyDaysWithLT32Temp',\n",
       " 'MonthlyDepartureFromNormalAverageTemperature',\n",
       " 'MonthlyDepartureFromNormalCoolingDegreeDays',\n",
       " 'MonthlyDepartureFromNormalHeatingDegreeDays',\n",
       " 'MonthlyDepartureFromNormalMaximumTemperature',\n",
       " 'MonthlyDepartureFromNormalMinimumTemperature',\n",
       " 'MonthlyDepartureFromNormalPrecipitation',\n",
       " 'MonthlyDewpointTemperature',\n",
       " 'MonthlyGreatestPrecip',\n",
       " 'MonthlyGreatestPrecipDate',\n",
       " 'MonthlyGreatestSnowDepth',\n",
       " 'MonthlyGreatestSnowDepthDate',\n",
       " 'MonthlyGreatestSnowfall',\n",
       " 'MonthlyGreatestSnowfallDate',\n",
       " 'MonthlyMaxSeaLevelPressureValue',\n",
       " 'MonthlyMaxSeaLevelPressureValueDate',\n",
       " 'MonthlyMaxSeaLevelPressureValueTime',\n",
       " 'MonthlyMaximumTemperature',\n",
       " 'MonthlyMeanTemperature',\n",
       " 'MonthlyMinSeaLevelPressureValue',\n",
       " 'MonthlyMinSeaLevelPressureValueDate',\n",
       " 'MonthlyMinSeaLevelPressureValueTime',\n",
       " 'MonthlyMinimumTemperature',\n",
       " 'MonthlySeaLevelPressure',\n",
       " 'MonthlyStationPressure',\n",
       " 'MonthlyTotalLiquidPrecipitation',\n",
       " 'MonthlyTotalSnowfall',\n",
       " 'MonthlyWetBulb',\n",
       " 'AWND',\n",
       " 'CDSD',\n",
       " 'CLDD',\n",
       " 'DSNW',\n",
       " 'HDSD',\n",
       " 'HTDD',\n",
       " 'DYTS',\n",
       " 'DYHF',\n",
       " 'NormalsCoolingDegreeDay',\n",
       " 'NormalsHeatingDegreeDay',\n",
       " 'ShortDurationEndDate005',\n",
       " 'ShortDurationEndDate010',\n",
       " 'ShortDurationEndDate015',\n",
       " 'ShortDurationEndDate020',\n",
       " 'ShortDurationEndDate030',\n",
       " 'ShortDurationEndDate045',\n",
       " 'ShortDurationEndDate060',\n",
       " 'ShortDurationEndDate080',\n",
       " 'ShortDurationEndDate100',\n",
       " 'ShortDurationEndDate120',\n",
       " 'ShortDurationEndDate150',\n",
       " 'ShortDurationEndDate180',\n",
       " 'ShortDurationPrecipitationValue005',\n",
       " 'ShortDurationPrecipitationValue010',\n",
       " 'ShortDurationPrecipitationValue015',\n",
       " 'ShortDurationPrecipitationValue020',\n",
       " 'ShortDurationPrecipitationValue030',\n",
       " 'ShortDurationPrecipitationValue045',\n",
       " 'ShortDurationPrecipitationValue060',\n",
       " 'ShortDurationPrecipitationValue080',\n",
       " 'ShortDurationPrecipitationValue100',\n",
       " 'ShortDurationPrecipitationValue120',\n",
       " 'ShortDurationPrecipitationValue150',\n",
       " 'ShortDurationPrecipitationValue180',\n",
       " 'REM',\n",
       " 'BackupDirection',\n",
       " 'BackupDistance',\n",
       " 'BackupDistanceUnit',\n",
       " 'BackupElements',\n",
       " 'BackupElevation',\n",
       " 'BackupEquipment',\n",
       " 'BackupLatitude',\n",
       " 'BackupLongitude',\n",
       " 'BackupName',\n",
       " 'WindEquipmentChangeDate']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m combined_df\u001b[38;5;241m.\u001b[39mto_csv(output_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat(dfs)\n",
    "combined_df.to_csv(output_file, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

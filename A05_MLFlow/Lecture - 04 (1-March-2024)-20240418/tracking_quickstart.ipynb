{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow 5 minute Tracking Quickstart\n",
    "\n",
    "This notebook demonstrates using a local MLflow Tracking Server to log, register, and then load a model as a generic Python Function (pyfunc) to perform inference on a Pandas DataFrame.\n",
    "\n",
    "Throughout this notebook, we'll be using the MLflow fluent API to perform all interactions with the MLflow Tracking Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:35:14.575050Z",
     "start_time": "2024-02-29T12:35:12.283318Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the MLflow Tracking URI \n",
    "\n",
    "Depending on where you are running this notebook, your configuration may vary for how you initialize the interface with the MLflow Tracking Server. \n",
    "\n",
    "For this example, we're using a locally running tracking server, but other options are available (The easiest is to use the free managed service within [Databricks Community Edition](https://community.cloud.databricks.com/)). \n",
    "\n",
    "Please see [the guide to running notebooks here](https://www.mlflow.org/docs/latest/getting-started/running-notebooks/index.html) for more information on setting the tracking server uri and configuring access to either managed or self-managed MLflow tracking servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:35:19.667152Z",
     "start_time": "2024-02-29T12:35:19.661960Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: review the links mentioned above for guidance on connecting to a managed tracking server, such as the free Databricks Community Edition\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data and train a simple model\n",
    "\n",
    "For our quickstart, we're going to be using the familiar iris dataset that is included in scikit-learn. Following the split of the data, we're going to train a simple logistic regression classifier on the training data and calculate some error metrics on our holdout test data. \n",
    "\n",
    "Note that the only MLflow-related activities in this portion are around the fact that we're using a `param` dictionary to supply our model's hyperparameters; this is to make logging these settings easier when we're ready to log our model and its associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:35:33.247780Z",
     "start_time": "2024-02-29T12:35:33.187775Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model hyperparameters\n",
    "params = {\"solver\": \"lbfgs\", \"max_iter\": 1000, \"multi_class\": \"auto\", \"random_state\": 8888}\n",
    "\n",
    "# Train the model\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate accuracy as a target loss metric\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an MLflow Experiment\n",
    "\n",
    "In order to group any distinct runs of a particular project or idea together, we can define an Experiment that will group each iteration (runs) together. \n",
    "Defining a unique name that is relevant to what we're working on helps with organization and reduces the amount of work (searching) to find our runs later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:35:36.414301Z",
     "start_time": "2024-02-29T12:35:36.243443Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/19 15:10:56 INFO mlflow.tracking.fluent: Experiment with name 'MLflow Quickstart' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/871618089907877873', creation_time=1713519656587, experiment_id='871618089907877873', last_update_time=1713519656587, lifecycle_stage='active', name='MLflow Quickstart', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"MLflow Quickstart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log the model, hyperparameters, and loss metrics to MLflow.\n",
    "\n",
    "In order to record our model and the hyperparameters that were used when fitting the model, as well as the metrics associated with validating the fit model upon holdout data, we initiate a run context, as shown below. Within the scope of that context, any fluent API that we call (such as `mlflow.log_params()` or `mlflow.sklearn.log_model()`) will be associated and logged together to the same run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:35:57.115829Z",
     "start_time": "2024-02-29T12:35:52.526912Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'tracking-quickstart'.\n",
      "2024/04/19 15:11:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: tracking-quickstart, version 1\n",
      "Created version '1' of model 'tracking-quickstart'.\n"
     ]
    }
   ],
   "source": [
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Basic LR model for iris data\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, lr.predict(X_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=lr,\n",
    "        artifact_path=\"iris_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"tracking-quickstart\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our saved model as a Python Function\n",
    "\n",
    "Although we can load our model back as a native scikit-learn format with `mlflow.sklearn.load_model()`, below we are loading the model as a generic Python Function, which is how this model would be loaded for online model serving. We can still use the `pyfunc` representation for batch use cases, though, as is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/5174f795f31b44d6985c4ec17ccb8486/iris_model'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as given in mlflow\n",
    "# logged_model = 'runs:/5174f795f31b44d6985c4ec17ccb8486/iris_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:36:57.355291Z",
     "start_time": "2024-02-29T12:36:57.144650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad0cb3a701a46c187faee9d4e81718f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/19 15:13:10 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use our model to predict the iris class type on a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:37:10.047608Z",
     "start_time": "2024-02-29T12:37:10.022659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>actual_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                6.1               2.8                4.7               1.2   \n",
       "1                5.7               3.8                1.7               0.3   \n",
       "2                7.7               2.6                6.9               2.3   \n",
       "3                6.0               2.9                4.5               1.5   \n",
       "\n",
       "   actual_class  predicted_class  \n",
       "0             1                1  \n",
       "1             0                0  \n",
       "2             2                2  \n",
       "3             1                1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "# Convert X_test validation feature data to a Pandas DataFrame\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "\n",
    "# Add the actual classes to the DataFrame\n",
    "result[\"actual_class\"] = y_test\n",
    "\n",
    "# Add the model predictions to the DataFrame\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "result[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:40:36.446725Z",
     "start_time": "2024-02-29T12:40:36.169438Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the experiment id\n",
    "# mlflow.set_experiment(experiment_id=\"633869001621094455\")\n",
    "mlflow.set_experiment(experiment_id=\"871618089907877873\") # id copied from the experiment created at the top\n",
    "\n",
    "mlflow.autolog()\n",
    "db = load_diabetes()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# Create and train models.\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the test dataset.\n",
    "predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:40:38.534098Z",
     "start_time": "2024-02-29T12:40:38.524353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -65.77447347,   31.36387965,   24.05413237,   70.55223581,\n",
       "        -32.54588909,   50.57545716,  -62.6203199 ,  -98.98094571,\n",
       "         12.26728331,   27.09217225, -101.05267062,  -20.46158236,\n",
       "         24.74875545,   67.2082197 ,  151.51924937,  -72.90430527,\n",
       "         -1.738077  ,  -22.5216384 ,  104.12607441,  -50.02937591,\n",
       "         -5.54517688,  -31.6002215 ,  -10.71231096,   39.75104301,\n",
       "         83.59211755,   17.16782442,   30.80787624,  -26.85468867,\n",
       "        -36.38776715,   38.06669629,   35.21236579,    0.17086213,\n",
       "         17.35460572,   51.92300942,   -1.14400925,    0.69476586,\n",
       "         33.27404457,   15.89152337,   77.72810607,  -52.41485456,\n",
       "         20.1867875 ,   63.52380027,   72.88222966,   70.39362493,\n",
       "         26.43633268,   83.8365238 ,   62.84479761,   62.50512031,\n",
       "         -1.72087733,   40.26830967,   95.27684747,  -41.87358517,\n",
       "         37.3277036 ,   65.95774518,   37.3943017 ,  -46.92056702,\n",
       "        -50.465869  ,   13.90504247,   84.61384742,  -28.67831482,\n",
       "         59.17752611,   24.06462398,  -54.99448425,   82.79440883,\n",
       "          5.34496682,   26.71668751,  -89.1557602 ,   51.10889862,\n",
       "          8.79558787, -121.10449918,  -37.63736035,  -98.54030256,\n",
       "        -43.76739813,  -62.85740666,    7.15913701,  -59.3227458 ,\n",
       "       -107.05176358,   37.41886893,  -64.72123255,    2.0830481 ,\n",
       "        -54.04252329,  -85.25269402,   46.85308696,   82.75913745,\n",
       "         55.70887811,    2.60337805,   32.87421986, -104.85007098,\n",
       "         61.05704149,    6.41755802, -165.39689769,   36.89778652,\n",
       "         65.63200413,   10.94176978,  -76.11471344,   53.35358169,\n",
       "         50.81612139,  -56.83913998,   76.08842075,  -33.24536883,\n",
       "        -78.6845474 ,   41.97288786,  -89.96957013,  102.95729643,\n",
       "        -38.71599964,   45.72568061,    1.73994185,   84.89773708,\n",
       "        -38.63577075,  -62.07936705,   33.83432843])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
